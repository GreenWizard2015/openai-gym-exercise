# Pendulum Environment

![](pendulum.png)

Одно из самых простых окружений/игр из OpenAI Gym. Состояние описано тремя значениями:
- косинус и синус текущего угла поворота.
- текущая скорость вращения.

Управляется окружение одним значением - "сила" прилагаемая в текущий момент.

**PendulumEnvironment.py** - обёртка над стандартным окружением. Текущая скорость нормализируется до диапазона -1..1. Прилагаемая сила так же приводится к -1..1. Награда отдаётся в виде дельты между старой и новой наградой (которая является очками за игру). Так же, предоставлен минимальный дополнительный функционал, который облегчает работу с окружением.

Основная цель: привести маятник в вертикальное положение,  из любого начального положения, и удерживать максимально долго (по-умолчанию, даётся 200 шагов на одну симуляцию).

Задача выглядит очень простой для человека, но требует интуитивного понимания физики и умения планировать. Например, раскачивание маятника из стороны в сторону является вполне логичным способом **в итоге** перевести маятник в вертикальное положение, но это, само по себе, кажется ошибкой: мы намеренно теряем очки, хоть цель в их наборе (мы разгоняем маятник двигая его в нижнюю точку, что уменьшает счёт).

**примечание**: окружение возвращает не непрерывную функцию наград. В некоторых точках награда резко изменяется, что может усложнить обучение. В `BasicPendulumEnvironment.py` реализована замена функции награды, новая функция просто считает расстояние до верхнего положения (точка [0, 1]). По-умолчанию возвращается стандартная награда.

**Внимание!** Скорее всего, я применил простейшую оптимизацию и случайно реализовал везде не DQN, a Double DQN с hard update в начале обучения.

[Простейший вариант DQN](DQN_v1)

[DQN с n-шагами предпросчёта](DQN_bootstrap)

[DQN с n-шагами предпросчёта + curiousity](DQN_curiosity)

[Dueling DQN с n-шагами предпросчёта](Dueling_DQN)